"""
RoBERTa Sentiment Analysis Server - IMPROVED VERSION
A Flask-based REST API server for sentiment analysis with enhanced neutral detection.

Installation:
pip install flask transformers torch scipy pandas flask-cors

Usage:
python server.py

API Endpoints:
- GET / - Serve HTML interface
- POST /analyze - Analyze single text
- POST /analyze_batch - Analyze multiple texts
- GET /health - Health check
"""

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
import logging
from typing import Dict, List

# ==========================
# ðŸ”§ Configuration
# ==========================
app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==========================
# ðŸ¤– Model Setup
# ==========================
MODEL_NAME = "cardiffnlp/twitter-roberta-base-sentiment"
device = "cuda" if torch.cuda.is_available() else "cpu"

logger.info(f"Loading model: {MODEL_NAME}")
logger.info(f"Using device: {device}")

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)
model.eval()

logger.info("âœ… Model loaded successfully")

# ==========================
# ðŸ’¬ Improved Sentiment Analysis Function
# ==========================
def sentiment_analysis_improved(text: str) -> Dict:
    """
    Compute sentiment with improved neutral detection.
    
    Uses multiple strategies:
    1. Weighted average for score
    2. Confidence thresholds for classification
    3. Neutral zone detection
    4. Mixed sentiment detection
    
    Args:
        text: Input text to analyze
        
    Returns:
        Dict with score, label, confidence, and probabilities
    """
    if not text or not text.strip():
        return {
            "score": 3.0,
            "label": "neutral",
            "confidence": 1.0,
            "probabilities": {"neg": 0.0, "neu": 1.0, "pos": 0.0}
        }
    
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        truncation=True, 
        padding=True,
        max_length=512
    ).to(device)

    with torch.no_grad():
        outputs = model(**inputs)
    
    logits = outputs.logits[0].cpu().numpy()
    probs = softmax(logits)  # [neg, neu, pos]

    p_neg, p_neu, p_pos = probs
    
    # Weighted average â†’ 1-5 scale
    score = 1 * p_neg + 3 * p_neu + 5 * p_pos
    
    # Improved classification logic
    # Strategy 1: High neutral probability (> 0.5)
    if p_neu > 0.5:
        label = "neutral"
    # Strategy 2: Balanced negative and positive (both > 0.2) = mixed/neutral
    elif p_neg > 0.2 and p_pos > 0.2:
        label = "neutral"
    # Strategy 3: Score-based thresholds with tighter ranges
    elif score >= 3.8:
        label = "positive"
    elif score <= 2.2:
        label = "negative"
    else:
        # In the neutral zone (2.2 - 3.8)
        # Check confidence: if no probability dominates, it's neutral
        max_prob = max(p_neg, p_neu, p_pos)
        if max_prob < 0.5:  # Low confidence
            label = "neutral"
        elif p_neu > p_neg and p_neu > p_pos:
            label = "neutral"
        elif score > 3.0:
            label = "slightly positive"
        else:
            label = "slightly negative"
    
    # Calculate confidence
    confidence = max(p_neg, p_neu, p_pos)
    
    return {
        "score": round(float(score), 2),
        "label": label,
        "confidence": round(float(confidence), 3),
        "probabilities": {
            "neg": round(float(p_neg), 3),
            "neu": round(float(p_neu), 3),
            "pos": round(float(p_pos), 3)
        }
    }

# ==========================
# ðŸŒ API Routes
# ==========================
@app.route("/")
def home():
    """Serve the main HTML page"""
    return render_template("example.html")

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "model": MODEL_NAME,
        "device": device,
        "version": "improved_v2"
    }), 200

@app.route('/analyze', methods=['POST'])
def analyze_sentiment():
    """
    Analyze sentiment of a single text with improved neutral detection.
    
    Request body:
    {
        "text": "Your text here"
    }
    
    Response:
    {
        "text": "Your text here",
        "sentiment_score": 3.2,
        "label": "neutral",
        "confidence": 0.85,
        "probabilities": {"neg": 0.05, "neu": 0.85, "pos": 0.10}
    }
    """
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({
                "error": "Missing 'text' field in request body"
            }), 400
        
        text = data['text']
        result = sentiment_analysis_improved(text)
        
        # Add the original text to the response
        result['text'] = text
        
        return jsonify(result), 200
        
    except Exception as e:
        logger.error(f"Error in analyze_sentiment: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/analyze_batch', methods=['POST'])
def analyze_batch():
    """
    Analyze sentiment of multiple texts with improved neutral detection.
    
    Request body:
    {
        "texts": ["text1", "text2", "text3"]
    }
    
    Response:
    {
        "results": [
            {
                "text": "text1",
                "sentiment_score": 3.2,
                "label": "neutral",
                "confidence": 0.85,
                "probabilities": {...}
            },
            ...
        ],
        "summary": {
            "total": 3,
            "positive": 1,
            "neutral": 1,
            "negative": 1,
            "average_score": 3.0,
            "average_confidence": 0.75
        }
    }
    """
    try:
        data = request.get_json()
        
        if not data or 'texts' not in data:
            return jsonify({
                "error": "Missing 'texts' field in request body"
            }), 400
        
        texts = data['texts']
        
        if not isinstance(texts, list):
            return jsonify({
                "error": "'texts' must be a list"
            }), 400
        
        results = []
        label_counts = {"positive": 0, "slightly positive": 0, "neutral": 0, 
                       "slightly negative": 0, "negative": 0}
        total_score = 0
        total_confidence = 0
        
        for text in texts:
            result = sentiment_analysis_improved(text)
            result['text'] = text
            results.append(result)
            
            # Update statistics
            label_counts[result['label']] = label_counts.get(result['label'], 0) + 1
            total_score += result['score']
            total_confidence += result['confidence']
        
        # Calculate summary statistics
        num_texts = len(texts)
        summary = {
            "total": num_texts,
            "label_distribution": label_counts,
            "average_score": round(total_score / num_texts, 2) if num_texts > 0 else 0,
            "average_confidence": round(total_confidence / num_texts, 3) if num_texts > 0 else 0
        }
        
        return jsonify({
            "results": results,
            "summary": summary
        }), 200
        
    except Exception as e:
        logger.error(f"Error in analyze_batch: {str(e)}")
        return jsonify({"error": str(e)}), 500

# ==========================
# ðŸš€ Run Server
# ==========================
if __name__ == '__main__':
    app.run(
        host='0.0.0.0',
        port=5000,
        debug=False  # Set to True for development
    )